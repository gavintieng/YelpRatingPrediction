{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType, MapType\n",
    "from pyspark.sql.functions import col, expr, when\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import pyspark.sql.functions as f\n",
    "from functools import reduce\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "\n",
    "\n",
    "\n",
    "# spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Modeling\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline of Model Building \n",
    "\n",
    "#### 1) Explore and choose potential predictors, put them into a separate dataframe\n",
    "\n",
    "#### 2) Convert data from categorical to numerical\n",
    "\n",
    "#### 3) Try 2 different strategies for dealing with NULL/missing values\n",
    "- Strategy 1: Impute NULL values with the mode of column\n",
    "- Strategy 2: Drop all rows that contain NULL values\n",
    "\n",
    "#### 4) Construct 3 models using the data with imputed values (LogisticRegressionWithLBFGS, RandomForestClassifer, NaiveBayes)\n",
    "\n",
    "#### 5) Construct 3 models using the data with the dropped NULLs (LogisticRegressionWithLBFGS, RandomForestClassifer, NaiveBayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from parquet file\n",
    "dineSafe_yelp_data = spark.read.parquet('data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ds_address: string (nullable = true)\n",
      " |-- ds_id: string (nullable = true)\n",
      " |-- ds_latitude: double (nullable = true)\n",
      " |-- ds_longitude: double (nullable = true)\n",
      " |-- ds_name: string (nullable = true)\n",
      " |-- ds_status: string (nullable = true)\n",
      " |-- ds_type: string (nullable = true)\n",
      " |-- ds_inspection: string (nullable = true)\n",
      " |-- ds_id_ins: string (nullable = true)\n",
      " |-- ds_pos_ins: string (nullable = true)\n",
      " |-- ds_date: string (nullable = true)\n",
      " |-- ds_status_ins: string (nullable = true)\n",
      " |-- ds_severity: string (nullable = true)\n",
      " |-- ds_action: string (nullable = true)\n",
      " |-- ds_subdatabase: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- attributes: struct (nullable = true)\n",
      " |    |-- AcceptsInsurance: string (nullable = true)\n",
      " |    |-- AgesAllowed: string (nullable = true)\n",
      " |    |-- Alcohol: string (nullable = true)\n",
      " |    |-- Ambience: string (nullable = true)\n",
      " |    |-- BYOB: string (nullable = true)\n",
      " |    |-- BYOBCorkage: string (nullable = true)\n",
      " |    |-- BestNights: string (nullable = true)\n",
      " |    |-- BikeParking: string (nullable = true)\n",
      " |    |-- BusinessAcceptsBitcoin: string (nullable = true)\n",
      " |    |-- BusinessAcceptsCreditCards: string (nullable = true)\n",
      " |    |-- BusinessParking: string (nullable = true)\n",
      " |    |-- ByAppointmentOnly: string (nullable = true)\n",
      " |    |-- Caters: string (nullable = true)\n",
      " |    |-- CoatCheck: string (nullable = true)\n",
      " |    |-- Corkage: string (nullable = true)\n",
      " |    |-- DietaryRestrictions: string (nullable = true)\n",
      " |    |-- DogsAllowed: string (nullable = true)\n",
      " |    |-- DriveThru: string (nullable = true)\n",
      " |    |-- GoodForDancing: string (nullable = true)\n",
      " |    |-- GoodForKids: string (nullable = true)\n",
      " |    |-- GoodForMeal: string (nullable = true)\n",
      " |    |-- HairSpecializesIn: string (nullable = true)\n",
      " |    |-- HappyHour: string (nullable = true)\n",
      " |    |-- HasTV: string (nullable = true)\n",
      " |    |-- Music: string (nullable = true)\n",
      " |    |-- NoiseLevel: string (nullable = true)\n",
      " |    |-- Open24Hours: string (nullable = true)\n",
      " |    |-- OutdoorSeating: string (nullable = true)\n",
      " |    |-- RestaurantsAttire: string (nullable = true)\n",
      " |    |-- RestaurantsCounterService: string (nullable = true)\n",
      " |    |-- RestaurantsDelivery: string (nullable = true)\n",
      " |    |-- RestaurantsGoodForGroups: string (nullable = true)\n",
      " |    |-- RestaurantsPriceRange2: string (nullable = true)\n",
      " |    |-- RestaurantsReservations: string (nullable = true)\n",
      " |    |-- RestaurantsTableService: string (nullable = true)\n",
      " |    |-- RestaurantsTakeOut: string (nullable = true)\n",
      " |    |-- Smoking: string (nullable = true)\n",
      " |    |-- WheelchairAccessible: string (nullable = true)\n",
      " |    |-- WiFi: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- hours: struct (nullable = true)\n",
      " |    |-- Friday: string (nullable = true)\n",
      " |    |-- Monday: string (nullable = true)\n",
      " |    |-- Saturday: string (nullable = true)\n",
      " |    |-- Sunday: string (nullable = true)\n",
      " |    |-- Thursday: string (nullable = true)\n",
      " |    |-- Tuesday: string (nullable = true)\n",
      " |    |-- Wednesday: string (nullable = true)\n",
      " |-- is_open: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine schema \n",
    "dineSafe_yelp_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Possible Predictors to Include\n",
    "\n",
    "ds_severity, ds_status_ins, ds_action, review_count, RestaurantsDelivery, RestaurantsTakeOut, OutdoorSeating, BikeParking, RestaurantsPriceRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|ds_severity        |count|\n",
      "+-------------------+-----+\n",
      "|null               |613  |\n",
      "|C - Crucial        |28   |\n",
      "|NA - Not Applicable|57   |\n",
      "|M - Minor          |523  |\n",
      "|S - Significant    |180  |\n",
      "+-------------------+-----+\n",
      "\n",
      "+----------------+-----+\n",
      "|ds_status_ins   |count|\n",
      "+----------------+-----+\n",
      "|null            |14   |\n",
      "|Conditional Pass|97   |\n",
      "|Closed          |1    |\n",
      "|Pass            |1289 |\n",
      "+----------------+-----+\n",
      "\n",
      "+---------------------------+-----+\n",
      "|ds_action                  |count|\n",
      "+---------------------------+-----+\n",
      "|null                       |613  |\n",
      "|Ticket                     |14   |\n",
      "|Corrected During Inspection|156  |\n",
      "|Notice to Comply           |617  |\n",
      "|Summons                    |1    |\n",
      "+---------------------------+-----+\n",
      "\n",
      "+------------+-----+\n",
      "|review_count|count|\n",
      "+------------+-----+\n",
      "|26          |11   |\n",
      "|29          |11   |\n",
      "|65          |14   |\n",
      "|19          |18   |\n",
      "|54          |4    |\n",
      "|22          |22   |\n",
      "|7           |54   |\n",
      "|34          |11   |\n",
      "|188         |3    |\n",
      "|126         |4    |\n",
      "+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------------+-----+\n",
      "|RestaurantsDelivery|count|\n",
      "+-------------------+-----+\n",
      "|False              |643  |\n",
      "|null               |499  |\n",
      "|True               |259  |\n",
      "+-------------------+-----+\n",
      "\n",
      "+------------------+-----+\n",
      "|RestaurantsTakeOut|count|\n",
      "+------------------+-----+\n",
      "|False             |69   |\n",
      "|null              |340  |\n",
      "|True              |992  |\n",
      "+------------------+-----+\n",
      "\n",
      "+--------------+-----+\n",
      "|OutdoorSeating|count|\n",
      "+--------------+-----+\n",
      "|False         |568  |\n",
      "|null          |446  |\n",
      "|True          |387  |\n",
      "+--------------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|BikeParking|count|\n",
      "+-----------+-----+\n",
      "|False      |124  |\n",
      "|null       |519  |\n",
      "|True       |758  |\n",
      "+-----------+-----+\n",
      "\n",
      "+----------------------+-----+\n",
      "|RestaurantsPriceRange2|count|\n",
      "+----------------------+-----+\n",
      "|3                     |88   |\n",
      "|null                  |327  |\n",
      "|1                     |490  |\n",
      "|4                     |6    |\n",
      "|2                     |490  |\n",
      "+----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dineSafe_yelp_data.groupby('ds_severity').count().show(truncate=False)\n",
    "dineSafe_yelp_data.groupby('ds_status_ins').count().show(truncate=False)\n",
    "dineSafe_yelp_data.groupby('ds_action').count().show(truncate=False)\n",
    "dineSafe_yelp_data.groupby('review_count').count().show(10, truncate=False)\n",
    "dineSafe_yelp_data.groupby('attributes.RestaurantsDelivery').count().show(truncate=False)\n",
    "dineSafe_yelp_data.groupby('attributes.RestaurantsTakeOut').count().show(truncate=False)\n",
    "dineSafe_yelp_data.groupby('attributes.OutdoorSeating').count().show(truncate=False)\n",
    "dineSafe_yelp_data.groupby('attributes.BikeParking').count().show(truncate=False)\n",
    "dineSafe_yelp_data.groupby('attributes.RestaurantsPriceRange2').count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Dataframe with Selected Predictors and Response Variable\n",
    "\n",
    "Use spark.sql to create a new dataframe that only contains the predictors we want to train the model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+\n",
      "|rating|ds_severity|ds_status_ins|       ds_action|review_count|RestaurantsDelivery|RestaurantsTakeOut|OutdoorSeating|BikeParking|RestaurantsPriceRange2|\n",
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+\n",
      "|   bad|  M - Minor|         Pass|Notice to Comply|          41|               null|              True|          null|       True|                     3|\n",
      "|   bad|       null|         Pass|            null|          41|               null|              True|          null|       True|                     3|\n",
      "|   bad|       null|         Pass|            null|          41|               null|              True|          null|       True|                     3|\n",
      "|   bad|       null|         Pass|            null|          41|               null|              True|          null|       True|                     3|\n",
      "|  good|       null|         null|            null|           4|               null|             False|          null|       True|                     3|\n",
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dineSafe_yelp_data.createOrReplaceTempView(\"dineSafe_yelp_data\")\n",
    "ratings_df = spark.sql(\"SELECT rating, ds_severity, ds_status_ins, ds_action, review_count, attributes.RestaurantsDelivery, attributes.RestaurantsTakeOut, attributes.OutdoorSeating, attributes.BikeParking, attributes.RestaurantsPriceRange2 FROM dineSafe_yelp_data\")\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Missing/NULL Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 613 missing values in ds_severity.\n",
      "There are 14 missing values in ds_status_ins.\n",
      "There are 613 missing values in ds_action.\n",
      "There are 0 missing values in review_count.\n",
      "There are 499 missing values in RestaurantsDelivery.\n",
      "There are 340 missing values in RestaurantsTakeOut.\n",
      "There are 446 missing values in OutdoorSeating.\n",
      "There are 519 missing values in BikeParking.\n",
      "There are 327 missing values in RestaurantsPriceRange2.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} missing values in ds_severity.'.format(ratings_df.filter(ratings_df['ds_severity'].isNull()).count()))\n",
    "print('There are {} missing values in ds_status_ins.'.format(ratings_df.filter(ratings_df['ds_status_ins'].isNull()).count()))\n",
    "print('There are {} missing values in ds_action.'.format(ratings_df.filter(ratings_df['ds_action'].isNull()).count()))\n",
    "print('There are {} missing values in review_count.'.format(ratings_df.filter(ratings_df['review_count'].isNull()).count()))\n",
    "print('There are {} missing values in RestaurantsDelivery.'.format(ratings_df.filter(ratings_df['RestaurantsDelivery'].isNull()).count()))\n",
    "print('There are {} missing values in RestaurantsTakeOut.'.format(ratings_df.filter(ratings_df['RestaurantsTakeOut'].isNull()).count()))\n",
    "print('There are {} missing values in OutdoorSeating.'.format(ratings_df.filter(ratings_df['OutdoorSeating'].isNull()).count()))\n",
    "print('There are {} missing values in BikeParking.'.format(ratings_df.filter(ratings_df['BikeParking'].isNull()).count()))\n",
    "print('There are {} missing values in RestaurantsPriceRange2.'.format(ratings_df.filter(ratings_df['RestaurantsPriceRange2'].isNull()).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining missing values, we will only drop entire columns if more than half of their values are null or missing. Since each column has 1401 entries, we won't outright drop any column entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relabel Data from Categorical to Numerical\n",
    "\n",
    "We will relabel all the predictors with categorical variables into numerical ones as follows:\n",
    "\n",
    "- rating: bad = 0, neutral = 1, good = 2\n",
    "- ds_severity: NA = 0, minor = 1, significant = 2, crucial = 3\n",
    "- ds_status_ins: closed = 0, conditional pass = 1, pass = 2\n",
    "- ds_action: Ticket = 0, Corrected During Inspection = 1, Notice to Comply = 2, Summons = 3\n",
    "- review_count: keep\n",
    "- RestaurantsDeliery: false = 0, true = 1\n",
    "- RestaurantsTakeOut: false = 0, true = 1\n",
    "- OutdoorSeating: false = 0, true = 1\n",
    "- BikeParking: false = 0, true = 1\n",
    "- RestaurantPriceRange2: keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new features that match the labels above \n",
    "ratings_num = when(\n",
    "    col('rating')=='bad',0).when(\n",
    "    col('rating')=='neutral',1).when(\n",
    "    col('rating')=='good',2)\n",
    "\n",
    "ds_severity_num = when(\n",
    "    col('ds_severity')=='NA - Not Applicable',0).when(\n",
    "    col('ds_severity')=='M - Minor',1).when(\n",
    "    col('ds_severity')=='S - Significant',2).when(\n",
    "    col('ds_severity')=='C - Crucial',3)\n",
    "\n",
    "ds_status_ins_num = when(\n",
    "    col('ds_status_ins')=='Closed',0).when(\n",
    "    col('ds_status_ins')=='Conditional Pass',1).when(\n",
    "    col('ds_status_ins')=='Pass',2)\n",
    "\n",
    "ds_action_num = when(\n",
    "    col('ds_action') == 'Ticket', 0).when(\n",
    "    col('ds_action') == 'Corrected During Inspection', 1).when(\n",
    "    col('ds_action') == 'Notice to Comply', 2).when(\n",
    "    col('ds_action') == 'Summons', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+-------------------------+\n",
      "|rating|ds_severity|ds_status_ins|       ds_action|review_count|RestaurantsDelivery|RestaurantsTakeOut|OutdoorSeating|BikeParking|RestaurantsPriceRange2|rating_num|ds_severity_num|ds_status_ins_num|ds_action_num|restaurantsDelivery_num|restaurantsTakeOut_num|outdoorSeating_num|bikeParking_num|restaurantsPriceRange_num|\n",
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+-------------------------+\n",
      "|   bad|  M - Minor|         Pass|Notice to Comply|          41|               null|              True|          null|       True|                     3|         0|              1|                2|            2|                   null|                     1|              null|              1|                      3.0|\n",
      "|   bad|       null|         Pass|            null|          41|               null|              True|          null|       True|                     3|         0|           null|                2|         null|                   null|                     1|              null|              1|                      3.0|\n",
      "|   bad|       null|         Pass|            null|          41|               null|              True|          null|       True|                     3|         0|           null|                2|         null|                   null|                     1|              null|              1|                      3.0|\n",
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add columns for each numerical predictor\n",
    "ratings_df = ratings_df.withColumn('rating_num', ratings_num)\n",
    "ratings_df = ratings_df.withColumn('ds_severity_num', ds_severity_num)\n",
    "ratings_df = ratings_df.withColumn('ds_status_ins_num', ds_status_ins_num)\n",
    "ratings_df = ratings_df.withColumn('ds_action_num', ds_action_num)\n",
    "ratings_df = ratings_df.withColumn('restaurantsDelivery_num', F.when(ratings_df['RestaurantsDelivery'] == 'False', 0).when(ratings_df['RestaurantsDelivery'] == 'True', 1))\n",
    "ratings_df = ratings_df.withColumn('restaurantsTakeOut_num', F.when(ratings_df['RestaurantsTakeOut'] == 'False', 0).when(ratings_df['RestaurantsTakeout'] == 'True', 1))\n",
    "ratings_df = ratings_df.withColumn('outdoorSeating_num', F.when(ratings_df['OutdoorSeating'] == 'False', 0).when(ratings_df['OutdoorSeating'] == 'True', 1))\n",
    "ratings_df = ratings_df.withColumn('bikeParking_num', F.when(ratings_df['BikeParking'] == 'False', 0).when(ratings_df['BikeParking'] == 'True', 1))\n",
    "ratings_df = ratings_df.withColumn('restaurantsPriceRange_num', ratings_df['RestaurantsPriceRange2'].cast('double')) \n",
    "\n",
    "# print out updated dataframe (there should still be null values)\n",
    "ratings_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+------------+-------------------------+\n",
      "|rating_num|ds_severity_num|ds_status_ins_num|ds_action_num|restaurantsDelivery_num|restaurantsTakeOut_num|outdoorSeating_num|bikeParking_num|review_count|restaurantsPriceRange_num|\n",
      "+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+------------+-------------------------+\n",
      "|         0|              1|                2|            2|                   null|                     1|              null|              1|          41|                      3.0|\n",
      "|         0|           null|                2|         null|                   null|                     1|              null|              1|          41|                      3.0|\n",
      "|         0|           null|                2|         null|                   null|                     1|              null|              1|          41|                      3.0|\n",
      "|         0|           null|                2|         null|                   null|                     1|              null|              1|          41|                      3.0|\n",
      "|         2|           null|             null|         null|                   null|                     0|              null|              1|           4|                      3.0|\n",
      "+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe that only contains the numerically represented predictors\n",
    "pred_keep = ['rating_num','ds_severity_num','ds_status_ins_num', 'ds_action_num','restaurantsDelivery_num',\n",
    "             'restaurantsTakeOut_num','outdoorSeating_num','bikeParking_num','review_count','restaurantsPriceRange_num']\n",
    "\n",
    "ratings_final = ratings_df.select(pred_keep)\n",
    "ratings_final.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1: Impute Missing Values with Mode\n",
    "First we are going to try imputing missing values. Since the variables are categorical, we will use the mode of each predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|              Column|Mode|\n",
      "+--------------------+----+\n",
      "|          rating_num| 1.0|\n",
      "|     ds_severity_num| 1.0|\n",
      "|   ds_status_ins_num| 2.0|\n",
      "|       ds_action_num| 2.0|\n",
      "|restaurantsDelive...| 0.0|\n",
      "|restaurantsTakeOu...| 1.0|\n",
      "|  outdoorSeating_num| 0.0|\n",
      "|     bikeParking_num| 1.0|\n",
      "|        review_count|12.0|\n",
      "|restaurantsPriceR...| 2.0|\n",
      "+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the mode of each column and store in a dataframe\n",
    "\n",
    "feature_modes = reduce(\n",
    "    lambda ratingcol, modecol: ratingcol.union(modecol),\n",
    "    [\n",
    "        ratings_final.dropna().groupBy(i)\\\n",
    "            .count()\\\n",
    "             .sort(f.col(\"count\").desc())\\\n",
    "             .limit(1)\\\n",
    "             .select(\n",
    "                f.lit(i).alias(\"Column\"),\n",
    "                f.col(i).alias(\"Mode\")\n",
    "            ) \n",
    "        for i in ratings_final.columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "feature_modes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can replace the missing values in each column with that column's mode (there are no missing vals in reviewcount)\n",
    "ratings_final = ratings_final.fillna({'ds_severity_num':1.0})\n",
    "ratings_final = ratings_final.fillna({'ds_status_ins_num':2.0})\n",
    "ratings_final = ratings_final.fillna({'ds_action_num':2.0})\n",
    "ratings_final = ratings_final.fillna({'restaurantsDelivery_num':0.0})\n",
    "ratings_final = ratings_final.fillna({'restaurantsTakeOut_num':1.0})\n",
    "ratings_final = ratings_final.fillna({'outdoorSeating_num':0.0})\n",
    "ratings_final = ratings_final.fillna({'bikeParking_num':1.0})\n",
    "ratings_final = ratings_final.fillna({'restaurantsPriceRange_num':2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values in ds_severity_num.\n",
      "There are 0 missing values in ds_status_ins_num.\n",
      "There are 0 missing values in ds_action_num.\n",
      "There are 0 missing values in review_count.\n",
      "There are 0 missing values in restaurantsDelivery_num.\n",
      "There are 0 missing values in restaurantsTakeOut_num.\n",
      "There are 0 missing values in outdoorSeating_num.\n",
      "There are 0 missing values in bikeParking_num.\n",
      "There are 0 missing values in restaurantsPriceRange_num.\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print('There are {} missing values in ds_severity_num.'.format(ratings_final.filter(ratings_final['ds_severity_num'].isNull()).count()))\n",
    "print('There are {} missing values in ds_status_ins_num.'.format(ratings_final.filter(ratings_final['ds_status_ins_num'].isNull()).count()))\n",
    "print('There are {} missing values in ds_action_num.'.format(ratings_final.filter(ratings_final['ds_action_num'].isNull()).count()))\n",
    "print('There are {} missing values in review_count.'.format(ratings_final.filter(ratings_final['review_count'].isNull()).count()))\n",
    "print('There are {} missing values in restaurantsDelivery_num.'.format(ratings_final.filter(ratings_final['restaurantsDelivery_num'].isNull()).count()))\n",
    "print('There are {} missing values in restaurantsTakeOut_num.'.format(ratings_final.filter(ratings_final['restaurantsTakeOut_num'].isNull()).count()))\n",
    "print('There are {} missing values in outdoorSeating_num.'.format(ratings_final.filter(ratings_final['outdoorSeating_num'].isNull()).count()))\n",
    "print('There are {} missing values in bikeParking_num.'.format(ratings_final.filter(ratings_final['bikeParking_num'].isNull()).count()))\n",
    "print('There are {} missing values in restaurantsPriceRange_num.'.format(ratings_final.filter(ratings_final['restaurantsPriceRange_num'].isNull()).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed with the model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Features into 1 Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------------------+\n",
      "|rating_num|features                              |\n",
      "+----------+--------------------------------------+\n",
      "|0         |[1.0,2.0,2.0,0.0,1.0,0.0,1.0,41.0,3.0]|\n",
      "|0         |[1.0,2.0,2.0,0.0,1.0,0.0,1.0,41.0,3.0]|\n",
      "|0         |[1.0,2.0,2.0,0.0,1.0,0.0,1.0,41.0,3.0]|\n",
      "|0         |[1.0,2.0,2.0,0.0,1.0,0.0,1.0,41.0,3.0]|\n",
      "|2         |[1.0,2.0,2.0,0.0,0.0,0.0,1.0,4.0,3.0] |\n",
      "+----------+--------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new df with label and features columns\n",
    "assembler = VectorAssembler(inputCols=ratings_final.columns[1:],\n",
    "                           outputCol=\"features\")\n",
    "\n",
    "ratings_scaled = assembler.transform(ratings_final)\n",
    "ratings_scaled = ratings_scaled.select(['rating_num','features'])\n",
    "ratings_scaled.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) LogisticRegressionWithLBFGS Model (Imputed Data)\n",
    "First we are going to use LogisticRegressionWithLBFGS because it includes feature scaling and L2 regularization.\n",
    "\n",
    "In order to use LogisticRegressionWithLBFGS, we have to convert our dataframe to an RDD and use the labeledpoint format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which features to use (all)\n",
    "assembler_1 = VectorAssembler(inputCols=['ds_severity_num','ds_status_ins_num',\n",
    "                                          'ds_action_num','restaurantsDelivery_num',\n",
    "                                          'restaurantsTakeOut_num','outdoorSeating_num',\n",
    "                                         'bikeParking_num','review_count','restaurantsPriceRange_num'], outputCol=\"features\") \n",
    "\n",
    "transformed_1 = assembler_1.transform(ratings_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, DenseVector([1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 41.0, 3.0])),\n",
       " (0, DenseVector([1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 41.0, 3.0])),\n",
       " (0, DenseVector([1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 41.0, 3.0])),\n",
       " (0, DenseVector([1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 41.0, 3.0])),\n",
       " (2, DenseVector([1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 3.0]))]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to RDD, since MLlib uses RDDs not dataframe\n",
    "ratings_final_rdd = transformed_1.select(col(\"rating_num\"), col(\"features\")).rdd.map(tuple)\n",
    "ratings_final_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,41.0,3.0]),\n",
       " LabeledPoint(0.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,41.0,3.0]),\n",
       " LabeledPoint(0.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,41.0,3.0]),\n",
       " LabeledPoint(0.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,41.0,3.0]),\n",
       " LabeledPoint(2.0, [1.0,2.0,2.0,0.0,0.0,0.0,1.0,4.0,3.0])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to LabeledPoint type\n",
    "ratings_final_lp = ratings_final_rdd.map(lambda row:(row[0],Vectors.dense(row[1]))).map(lambda row:LabeledPoint(row[0],row[1]))\n",
    "ratings_final_lp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7880085653104925, 0.21199143468950749, 1.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split RDD into 80% train, 20% test\n",
    "ratings_train_lp, ratings_test_lp = ratings_final_lp.randomSplit([0.8, 0.2], seed=314)\n",
    "\n",
    "# check if split is approximately 80-20 train, test\n",
    "(ratings_train_lp.count()/ratings_final_lp.count(), ratings_test_lp.count()/ratings_final_lp.count(), ratings_final_lp.count()/ratings_final_lp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(2.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,4.0,2.0]),\n",
       " LabeledPoint(1.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,201.0,2.0]),\n",
       " LabeledPoint(1.0, [1.0,2.0,2.0,0.0,1.0,1.0,1.0,107.0,2.0]),\n",
       " LabeledPoint(1.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,71.0,2.0]),\n",
       " LabeledPoint(2.0, [1.0,2.0,2.0,0.0,1.0,1.0,1.0,40.0,2.0])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "ratings_model = LogisticRegressionWithLBFGS.train(ratings_train_lp,numClasses=3)\n",
    "ratings_test_lp.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of LogisticRegressionWithLBFGS Model (Imputed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Label = 0.0  Label = 1.0  Label = 2.0\n",
      "precision     0.439024     0.489083     0.370370\n",
      "recall        0.236842     0.842105     0.113636\n",
      "f1 score      0.307692     0.618785     0.173913\n",
      "=================================================\n",
      "Overall Model Accuracy (test): 0.4713804713804714\n"
     ]
    }
   ],
   "source": [
    "# map the prediction and label for each entry \n",
    "predictionAndLabels = ratings_test_lp.map(lambda lp: (float(ratings_model.predict(lp.features)), lp.label))                                 \n",
    "\n",
    "# create a metrics object based on predictions\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# create a dataframe to store model metrics for each label\n",
    "evaldata = {'Label = 0.0':[metrics.precision(label=0.0),metrics.recall(label=0.0),metrics.fMeasure(label=0.0)],\n",
    "            'Label = 1.0':[metrics.precision(label=1.0),metrics.recall(label=1.0),metrics.fMeasure(label=1.0)],\n",
    "            'Label = 2.0':[metrics.precision(label=2.0),metrics.recall(label=2.0),metrics.fMeasure(label=2.0)]}\n",
    "lbfgs_df = pd.DataFrame(evaldata,index=['precision','recall','f1 score'])\n",
    "labelsAndPreds_test = ratings_test_lp.map(lambda p: (p.label, ratings_model.predict(p.features)))\n",
    "accuracy_te = 1.0 * labelsAndPreds_test.filter(lambda pl: pl[0] == pl[1]).count() / ratings_test_lp.count()\n",
    "\n",
    "print(lbfgs_df)\n",
    "print('=================================================')\n",
    "print('Overall Model Accuracy (test): {}'.format(accuracy_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into 80% Training and 20% Testing Sets\n",
    "This split will be used for the RandomForestClassifier and NaiveBayes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 1106 observations.\n",
      "Testing set has 295 observations.\n"
     ]
    }
   ],
   "source": [
    "# split data \n",
    "seed=314\n",
    "train_test = [0.80, 0.20]\n",
    "ratings_train, ratings_test = ratings_scaled.randomSplit(train_test,seed=seed)\n",
    "\n",
    "print('Training set has {} observations.'.format(ratings_train.count()))\n",
    "print('Testing set has {} observations.'.format(ratings_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forest Classifier Model (Imputed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "ratings_rfc1 = RandomForestClassifier(numTrees=9, featuresCol='features',labelCol='rating_num')\n",
    "\n",
    "# fit model on training data\n",
    "ratings_rfc_model1 = ratings_rfc1.fit(ratings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|rating_num|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|         0|[0.0,2.0,2.0,0.0,...|[3.63063380677546...|[0.40340375630838...|       0.0|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on test data using Random Forest classifier\n",
    "ratings_rfc_pred1 = ratings_rfc_model1.transform(ratings_test)\n",
    "ratings_rfc_pred1.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Random Forest Model (Imputed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|rating_num|prediction|         probability|\n",
      "+----------+----------+--------------------+\n",
      "|         0|       0.0|[0.40340375630838...|\n",
      "|         0|       0.0|[0.43357633755891...|\n",
      "|         0|       2.0|[0.22378854620293...|\n",
      "|         0|       2.0|[0.32913569194417...|\n",
      "|         0|       0.0|[0.56408288601058...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_rfc_pred1.select('rating_num','prediction','probability').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using RandomForestClassifier with Imputed Values= 0.555932\n"
     ]
    }
   ],
   "source": [
    "eval = MulticlassClassificationEvaluator(labelCol='rating_num',predictionCol='prediction',metricName=\"accuracy\")\n",
    "acc_rfc_im = eval.evaluate(ratings_rfc_pred1)\n",
    "print('Accuracy using RandomForestClassifier with Imputed Values= %g' % (acc_rfc_im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Naive Bayes Classifier (Imputed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "ratings_nb1 = NaiveBayes(smoothing=0.5, modelType='multinomial',labelCol='rating_num',featuresCol='features')\n",
    "\n",
    "# fit on training data\n",
    "ratings_nb_model1 = ratings_nb1.fit(ratings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|rating_num|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|         0|[0.0,2.0,2.0,0.0,...|[-27.562421848768...|[0.65156041508465...|       0.0|\n",
      "|         0|[0.0,2.0,2.0,0.0,...|[-25.345883237094...|[0.58543790393481...|       0.0|\n",
      "|         0|[0.0,2.0,2.0,0.0,...|[-32.444180692090...|[0.61587495829703...|       0.0|\n",
      "|         0|[1.0,2.0,1.0,0.0,...|[-28.904190675738...|[0.63934097509873...|       0.0|\n",
      "|         0|[1.0,2.0,1.0,0.0,...|[-26.978824177823...|[0.54955311034679...|       0.0|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on test data using Naive Bayes classifier\n",
    "ratings_nb_pred1 =  ratings_nb_model1.transform(ratings_test)\n",
    "ratings_nb_pred1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Naive Bayes Model (Imputed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Naive Bayes Classifier with Imputed Values=  = 0.427119\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eval = MulticlassClassificationEvaluator(labelCol='rating_num',predictionCol='prediction',metricName=\"accuracy\")\n",
    "acc_nb_im = eval.evaluate(ratings_nb_pred1)\n",
    "print('Accuracy using Naive Bayes Classifier with Imputed Values=  = %g' % (acc_nb_im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 2: Drop Rows that Contain Null/Missing values\n",
    "We can see how the model performs if we were to drop all the null values instead of imputing them with the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+\n",
      "|rating|ds_severity|ds_status_ins|       ds_action|review_count|RestaurantsDelivery|RestaurantsTakeOut|OutdoorSeating|BikeParking|RestaurantsPriceRange2|\n",
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+\n",
      "|   bad|  M - Minor|         Pass|Notice to Comply|          41|               null|              True|          null|       True|                     3|\n",
      "|   bad|       null|         Pass|            null|          41|               null|              True|          null|       True|                     3|\n",
      "|   bad|       null|         Pass|            null|          41|               null|              True|          null|       True|                     3|\n",
      "|   bad|       null|         Pass|            null|          41|               null|              True|          null|       True|                     3|\n",
      "|  good|       null|         null|            null|           4|               null|             False|          null|       True|                     3|\n",
      "+------+-----------+-------------+----------------+------------+-------------------+------------------+--------------+-----------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe\n",
    "dineSafe_yelp_data.createOrReplaceTempView(\"dineSafe_yelp_data\")\n",
    "ratings_df_2 = spark.sql(\"SELECT rating, ds_severity, ds_status_ins, ds_action, review_count, attributes.RestaurantsDelivery, attributes.RestaurantsTakeOut, attributes.OutdoorSeating, attributes.BikeParking, attributes.RestaurantsPriceRange2 FROM dineSafe_yelp_data\")\n",
    "ratings_df_2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 592 rows that contain NULL/missing values in ratings_df_2.\n",
      "After .na.drop(), there are 0 rows that contain NULL/missing values in ratings_df_2_fixed.\n"
     ]
    }
   ],
   "source": [
    "# drop missing values\n",
    "print('There are {} rows that contain NULL/missing values in ratings_df_2.'.format(ratings_df_2.subtract(ratings_df_2.na.drop()).count()))\n",
    "ratings_df_2_fixed=ratings_df_2.na.drop()\n",
    "print('After .na.drop(), there are {} rows that contain NULL/missing values in ratings_df_2_fixed.'.format(ratings_df_2_fixed.subtract(ratings_df_2_fixed.dropna()).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns that represent the predictors numerically\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('rating_num', ratings_num)\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('ds_severity_num', ds_severity_num)\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('ds_status_ins_num', ds_status_ins_num)\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('ds_action_num', ds_action_num)\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('restaurantsDelivery_num', F.when(ratings_df_2_fixed['RestaurantsDelivery'] == 'False', 0).when(ratings_df_2_fixed['RestaurantsDelivery'] == 'True', 1))\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('restaurantsTakeOut_num', F.when(ratings_df_2_fixed['RestaurantsTakeOut'] == 'False', 0).when(ratings_df_2_fixed['RestaurantsTakeout'] == 'True', 1))\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('outdoorSeating_num', F.when(ratings_df_2_fixed['OutdoorSeating'] == 'False', 0).when(ratings_df_2_fixed['OutdoorSeating'] == 'True', 1))\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('bikeParking_num', F.when(ratings_df_2_fixed['BikeParking'] == 'False', 0).when(ratings_df_2_fixed['BikeParking'] == 'True', 1))\n",
    "ratings_df_2_fixed = ratings_df_2_fixed.withColumn('restaurantsPriceRange_num', ratings_df_2_fixed['RestaurantsPriceRange2'].cast('double')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+------------+-------------------------+\n",
      "|rating_num|ds_severity_num|ds_status_ins_num|ds_action_num|restaurantsDelivery_num|restaurantsTakeOut_num|outdoorSeating_num|bikeParking_num|review_count|restaurantsPriceRange_num|\n",
      "+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+------------+-------------------------+\n",
      "|         2|              1|                2|            2|                      0|                     1|                 1|              1|          13|                      2.0|\n",
      "|         2|              2|                1|            2|                      0|                     1|                 1|              1|          13|                      2.0|\n",
      "|         1|              2|                1|            2|                      0|                     1|                 0|              1|         201|                      2.0|\n",
      "+----------+---------------+-----------------+-------------+-----------------------+----------------------+------------------+---------------+------------+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe that only contains the numerically represented predictors\n",
    "pred_keep_2 = ['rating_num','ds_severity_num','ds_status_ins_num', 'ds_action_num','restaurantsDelivery_num',\n",
    "             'restaurantsTakeOut_num','outdoorSeating_num','bikeParking_num','review_count','restaurantsPriceRange_num']\n",
    "ratings_2_final = ratings_df_2_fixed.select(pred_keep_2)\n",
    "ratings_2_final.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Features into 1 Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------------+\n",
      "|rating_num|features                               |\n",
      "+----------+---------------------------------------+\n",
      "|2         |[1.0,2.0,2.0,0.0,1.0,1.0,1.0,13.0,2.0] |\n",
      "|2         |[2.0,1.0,2.0,0.0,1.0,1.0,1.0,13.0,2.0] |\n",
      "|1         |[2.0,1.0,2.0,0.0,1.0,0.0,1.0,201.0,2.0]|\n",
      "|1         |[1.0,2.0,2.0,0.0,1.0,0.0,1.0,201.0,2.0]|\n",
      "|1         |[1.0,2.0,2.0,0.0,1.0,0.0,1.0,201.0,2.0]|\n",
      "+----------+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new df with label and features columns\n",
    "assembler = VectorAssembler(inputCols=ratings_2_final.columns[1:],\n",
    "                           outputCol=\"features\")\n",
    "\n",
    "ratings_2_scaled = assembler.transform(ratings_2_final)\n",
    "ratings_2_scaled = ratings_2_scaled.select(['rating_num','features'])\n",
    "ratings_2_scaled.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) LogisticRegressionWithLBFGS Model (with dropped NULL values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which features to use (all)\n",
    "assembler_2 = VectorAssembler(inputCols=['ds_severity_num','ds_status_ins_num',\n",
    "                                          'ds_action_num','restaurantsDelivery_num',\n",
    "                                          'restaurantsTakeOut_num','outdoorSeating_num',\n",
    "                                         'bikeParking_num','review_count','restaurantsPriceRange_num'], outputCol=\"features\") \n",
    "\n",
    "transformed_2 = assembler_2.transform(ratings_2_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, DenseVector([1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 13.0, 2.0])),\n",
       " (2, DenseVector([2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 13.0, 2.0])),\n",
       " (1, DenseVector([2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 201.0, 2.0])),\n",
       " (1, DenseVector([1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 201.0, 2.0])),\n",
       " (1, DenseVector([1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 201.0, 2.0]))]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to RDD, since MLlib uses RDDs not dataframe\n",
    "ratings_final_rdd_2 = transformed_2.select(col(\"rating_num\"), col(\"features\")).rdd.map(tuple)\n",
    "ratings_final_rdd_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(2.0, [1.0,2.0,2.0,0.0,1.0,1.0,1.0,13.0,2.0]),\n",
       " LabeledPoint(2.0, [2.0,1.0,2.0,0.0,1.0,1.0,1.0,13.0,2.0]),\n",
       " LabeledPoint(1.0, [2.0,1.0,2.0,0.0,1.0,0.0,1.0,201.0,2.0]),\n",
       " LabeledPoint(1.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,201.0,2.0]),\n",
       " LabeledPoint(1.0, [1.0,2.0,2.0,0.0,1.0,0.0,1.0,201.0,2.0])]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to LabeledPoint type\n",
    "ratings_final_lp_2 = ratings_final_rdd_2.map(lambda row:(row[0],Vectors.dense(row[1]))).map(lambda row:LabeledPoint(row[0],row[1]))\n",
    "ratings_final_lp_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7945205479452054, 0.2054794520547945, 1.0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split RDD into 80% train, 20% test\n",
    "ratings_train_lp_2, ratings_test_lp_2 = ratings_final_lp_2.randomSplit([0.8, 0.2], seed=314)\n",
    "\n",
    "# check if split is approximately 80-20 train, test\n",
    "(ratings_train_lp_2.count()/ratings_final_lp_2.count(), ratings_test_lp_2.count()/ratings_final_lp_2.count(), ratings_final_lp_2.count()/ratings_final_lp_2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [2.0,2.0,1.0,0.0,1.0,0.0,1.0,71.0,2.0]),\n",
       " LabeledPoint(2.0, [1.0,2.0,2.0,0.0,1.0,0.0,0.0,119.0,2.0]),\n",
       " LabeledPoint(1.0, [0.0,2.0,2.0,0.0,1.0,1.0,1.0,49.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,2.0,2.0,1.0,1.0,0.0,1.0,27.0,1.0]),\n",
       " LabeledPoint(1.0, [1.0,2.0,2.0,1.0,1.0,0.0,1.0,12.0,1.0])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model \n",
    "ratings_model_2 = LogisticRegressionWithLBFGS.train(ratings_train_lp_2,numClasses=3)\n",
    "ratings_test_lp_2.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of LogisticRegressionWithLBFGS Model (with dropped NULL values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Label = 0.0  Label = 1.0  Label = 2.0\n",
      "precision     0.333333     0.532258          0.0\n",
      "recall        0.210526     0.868421          0.0\n",
      "f1 score      0.258065     0.660000          0.0\n",
      "=================================================\n",
      "Overall Model Accuracy (test): 0.49333333333333335\n"
     ]
    }
   ],
   "source": [
    "# map the prediction and label for each entry \n",
    "predictionAndLabels2 = ratings_test_lp_2.map(lambda lp: (float(ratings_model_2.predict(lp.features)), lp.label))                                 \n",
    "\n",
    "# create a metrics object based on predictions\n",
    "metrics2 = MulticlassMetrics(predictionAndLabels2)\n",
    "\n",
    "# create a dataframe to store model metrics for each label\n",
    "evaldata2 = {'Label = 0.0':[metrics2.precision(label=0.0),metrics2.recall(label=0.0),metrics2.fMeasure(label=0.0)],\n",
    "            'Label = 1.0':[metrics2.precision(label=1.0),metrics2.recall(label=1.0),metrics2.fMeasure(label=1.0)],\n",
    "            'Label = 2.0':[metrics2.precision(label=2.0),metrics2.recall(label=2.0),metrics2.fMeasure(label=2.0)]}\n",
    "lbfgs_df2 = pd.DataFrame(evaldata2,index=['precision','recall','f1 score'])\n",
    "labelsAndPreds_test2 = ratings_test_lp_2.map(lambda p: (p.label, ratings_model_2.predict(p.features)))\n",
    "accuracy_te2 = 1.0 * labelsAndPreds_test2.filter(lambda pl: pl[0] == pl[1]).count() / ratings_test_lp_2.count()\n",
    "\n",
    "print(lbfgs_df2)\n",
    "print('=================================================')\n",
    "print('Overall Model Accuracy (test): {}'.format(accuracy_te2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into 80% Training and 20% Testing Sets (with dropped NULL values)\n",
    "This split will be used for the RandomForestClassifier and NaiveBayes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 289 observations.\n",
      "Testing set has 76 observations.\n"
     ]
    }
   ],
   "source": [
    "seed=314\n",
    "train_test = [0.80, 0.20]\n",
    "ratings_train, ratings_test = ratings_2_scaled.randomSplit(train_test,seed=seed)\n",
    "\n",
    "print('Training set has {} observations.'.format(ratings_train.count()))\n",
    "print('Testing set has {} observations.'.format(ratings_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forest Classifier (with dropped NULL values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "ratings_rfc2 = RandomForestClassifier(numTrees=9, featuresCol='features',labelCol='rating_num')\n",
    "\n",
    "# fit model on training data\n",
    "ratings_rfc_model2 = ratings_rfc2.fit(ratings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|rating_num|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|         0|[1.0,1.0,2.0,0.0,...|[1.70215657019686...|[0.18912850779965...|       1.0|\n",
      "|         0|[1.0,2.0,1.0,0.0,...|[3.57669495635402...|[0.39741055070600...|       1.0|\n",
      "|         0|[1.0,2.0,2.0,0.0,...|[3.70560109289617...|[0.41173345476624...|       0.0|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on test data using Random Forest classifier\n",
    "ratings_rfc_pred2 = ratings_rfc_model2.transform(ratings_test)\n",
    "ratings_rfc_pred2.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Random Forest Classifier Model (with dropped NULL values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifier Model (with dropped NULL values) = 0.671053\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eval = MulticlassClassificationEvaluator(labelCol='rating_num',predictionCol='prediction',metricName=\"accuracy\")\n",
    "acc_rfc = eval.evaluate(ratings_rfc_pred2)\n",
    "print('Accuracy for Random Forest Classifier Model (with dropped NULL values) = %g' % (acc_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Naive Bayes Classifier (with dropped NULL values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "ratings_nb2 = NaiveBayes(smoothing=0.5, modelType='multinomial',labelCol='rating_num',featuresCol='features')\n",
    "\n",
    "# fit on training data\n",
    "ratings_nb_model2 = ratings_nb2.fit(ratings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|rating_num|            features|       rawPrediction|         probability|prediction|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "|         0|[1.0,1.0,2.0,0.0,...|[-37.916116355028...|[0.20661779230043...|       1.0|\n",
      "|         0|[1.0,2.0,1.0,0.0,...|[-30.335501127766...|[0.25104515800018...|       1.0|\n",
      "|         0|[1.0,2.0,2.0,0.0,...|[-30.433046029020...|[0.28394162720222...|       1.0|\n",
      "+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on test data using Naive Bayes classifier\n",
    "ratings_nb_pred2 =  ratings_nb_model2.transform(ratings_test)\n",
    "ratings_nb_pred2.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Naive Bayes Classifer (with dropped NULL values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes Classifier Model (with dropped NULL values) = 0.552632\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eval = MulticlassClassificationEvaluator(labelCol='rating_num',predictionCol='prediction',metricName=\"accuracy\")\n",
    "acc_nb = eval.evaluate(ratings_nb_pred2)\n",
    "print('Accuracy for Naive Bayes Classifier Model (with dropped NULL values) = %g' % (acc_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of 3 models With/Without Imputed Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Dropped NULL Values</th>\n",
       "      <th>Using Imputed Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegressionWithLBGFS</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.447458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.555932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.427119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy  Dropped NULL Values  Using Imputed Data\n",
       "0  LogisticRegressionWithLBGFS             0.618421            0.447458\n",
       "1       RandomForestClassifier             0.671053            0.555932\n",
       "2                   NaiveBayes             0.552632            0.427119"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct dataframe of accuracy for each model\n",
    "acc_noimpute_arr = [acc_lr,acc_rfc,acc_nb]\n",
    "acc_impute_arr = [acc_lr_im,acc_rfc_im,acc_nb_im]\n",
    "acc_labels = ['LogisticRegressionWithLBGFS','RandomForestClassifier','NaiveBayes']\n",
    "acc_df = pd.DataFrame(acc_labels)\n",
    "acc_df.columns=['Accuracy']\n",
    "acc_df['Dropped NULL Values']=acc_noimpute_arr\n",
    "acc_df['Using Imputed Data']=acc_impute_arr\n",
    "\n",
    "acc_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
